{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from k_fold import *\n",
    "from splitData import *\n",
    "from algos.polynomial_regression import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data extraction\n",
    "data = []\n",
    "with open('temp_pre.csv', mode='r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        data.append([int(row[\"temperature\"]), float(row[\"pressure\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.63835604 -0.56760068]\n",
      " [-1.44560827 -0.56759411]\n",
      " [-1.2528605  -0.5675626 ]\n",
      " [-1.06011273 -0.56740506]\n",
      " [-0.86736496 -0.56701119]\n",
      " [-0.67461719 -0.5658296 ]\n",
      " [-0.48186942 -0.56267868]\n",
      " [-0.28912165 -0.55545782]\n",
      " [-0.09637388 -0.54003145]\n",
      " [ 0.09637388 -0.50983515]\n",
      " [ 0.28912165 -0.45403764]\n",
      " [ 0.48186942 -0.35688432]\n",
      " [ 0.67461719 -0.19343043]\n",
      " [ 0.86736496  0.06258169]\n",
      " [ 1.06011273  0.4630109 ]\n",
      " [ 1.2528605   1.0538081 ]\n",
      " [ 1.44560827  1.90061742]\n",
      " [ 1.63835604  3.09534064]]\n"
     ]
    }
   ],
   "source": [
    "# data normalization\n",
    "# Z-value transformer\n",
    "def Zvalue(x,mean,std):\n",
    "    return (x - mean)/std\n",
    "\n",
    "def dataNormalize(data):\n",
    "    X = np.asarray(data)\n",
    "    mean, std = [], []\n",
    "    for i in range(X.shape[1]):\n",
    "        mean.append(np.mean(X[:,i]))\n",
    "        std.append(np.std(X[:,i]))\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(0,X.shape[1]):\n",
    "            X[i][j] = Zvalue(X[i][j],mean[j],std[j])\n",
    "    return X\n",
    "\n",
    "# data normalization\n",
    "data = dataNormalize(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set:\n",
      " [[-1.63835604 -0.56760068]\n",
      " [-1.44560827 -0.56759411]\n",
      " [-1.2528605  -0.5675626 ]\n",
      " [-1.06011273 -0.56740506]\n",
      " [-0.67461719 -0.5658296 ]\n",
      " [-0.28912165 -0.55545782]\n",
      " [-0.09637388 -0.54003145]\n",
      " [ 0.09637388 -0.50983515]\n",
      " [ 0.28912165 -0.45403764]\n",
      " [ 0.67461719 -0.19343043]\n",
      " [ 0.86736496  0.06258169]\n",
      " [ 1.06011273  0.4630109 ]\n",
      " [ 1.2528605   1.0538081 ]\n",
      " [ 1.44560827  1.90061742]\n",
      " [ 1.63835604  3.09534064]]\n",
      "validation set\n",
      " [[ 0.48186942 -0.35688432]\n",
      " [-0.86736496 -0.56701119]\n",
      " [-0.48186942 -0.56267868]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split data into 80% training and 20% validation sets\n",
    "train, valid = split(data)\n",
    "print(\"training set:\\n\",train)\n",
    "print(\"validation set\\n\", valid)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x:\n",
      " [[-1.63835604]\n",
      " [-1.44560827]\n",
      " [-1.2528605 ]\n",
      " [-1.06011273]\n",
      " [-0.67461719]\n",
      " [-0.28912165]\n",
      " [-0.09637388]\n",
      " [ 0.09637388]\n",
      " [ 0.28912165]\n",
      " [ 0.67461719]\n",
      " [ 0.86736496]\n",
      " [ 1.06011273]\n",
      " [ 1.2528605 ]\n",
      " [ 1.44560827]\n",
      " [ 1.63835604]]\n",
      "train_y:\n",
      " [-0.56760068 -0.56759411 -0.5675626  -0.56740506 -0.5658296  -0.55545782\n",
      " -0.54003145 -0.50983515 -0.45403764 -0.19343043  0.06258169  0.4630109\n",
      "  1.0538081   1.90061742  3.09534064]\n",
      "val_x:\n",
      " [[ 0.48186942]\n",
      " [-0.86736496]\n",
      " [-0.48186942]]\n",
      "val_y:\n",
      " [-0.35688432 -0.56701119 -0.56267868]\n"
     ]
    }
   ],
   "source": [
    "train, valid = np.asarray(train), np.asarray(valid)\n",
    "train_x = train[:,:-1] # extract x from train\n",
    "train_y = train[:,-1] # extract y from train\n",
    "val_x = valid[:,:-1] # extract x from validation\n",
    "val_y = valid[:,-1] # extract y from validation\n",
    "\n",
    "print(\"train_x:\\n\", train_x)\n",
    "print(\"train_y:\\n\", train_y)\n",
    "print(\"val_x:\\n\", val_x)\n",
    "print(\"val_y:\\n\", val_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL RESULTS:\n",
      "optimal weight vector:  [0.054372   0.77360067] \t| empirical loss:  0.471542\n"
     ]
    }
   ],
   "source": [
    "w0, ls = PolynomialRegression(train_x, train_y, 1) # linear regression with polynomial mapping of degree 1\n",
    "print(\"FINAL RESULTS:\")\n",
    "print(\"optimal weight vector: \", w0, \"\\t| empirical loss: \", \"{0:.6f}\".format(ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.48186942]\n",
      " [ 1.         -0.86736496]\n",
      " [ 1.         -0.48186942]] [-0.35688432 -0.56701119 -0.56267868] [0.054372   0.77360067]\n",
      "0.22561214894458867\n"
     ]
    }
   ],
   "source": [
    "# using the loss function to calculate the error\n",
    "val_x_1 = np.array([psy(x,1) for x in val_x])\n",
    "print(val_x_1, val_y, w0)\n",
    "los = loss(val_x_1,val_y,w0)\n",
    "print(los)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL RESULTS:\n",
      "optimal weight vector:  [-0.68075363  0.78607231  0.65637146] \t| empirical loss:  0.103681\n"
     ]
    }
   ],
   "source": [
    "w0, ls = PolynomialRegression(train_x, train_y, 2) # linear regression with polynomial mapping of degree 1\n",
    "print(\"FINAL RESULTS:\")\n",
    "print(\"optimal weight vector: \", w0, \"\\t| empirical loss: \", \"{0:.6f}\".format(ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08422773461461912\n"
     ]
    }
   ],
   "source": [
    "# using the loss function to calculate the error\n",
    "val_x_2 = np.array([psy(x,2) for x in val_x])\n",
    "los = loss(val_x_2, val_y, w0)\n",
    "print(los)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL RESULTS:\n",
      "optimal weight vector:  [-0.65111133  0.09332694  0.65131723  0.3723382 ] \t| empirical loss:  0.012099\n"
     ]
    }
   ],
   "source": [
    "w0, ls = PolynomialRegression(train_x, train_y, 3) # linear regression with polynomial mapping of degree 1\n",
    "print(\"FINAL RESULTS:\")\n",
    "print(\"optimal weight vector: \", w0, \"\\t| empirical loss: \", \"{0:.6f}\".format(ls))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation with k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please choose a k value among the following:\n",
      "2 3 6 9 18 \n"
     ]
    }
   ],
   "source": [
    "# cross-validation using k-folds\n",
    "part = k_fold(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal weight vector:  [[-0.24752609  0.38628457  0.41477359]\n",
      " [ 0.27208134 -0.14213015  1.14621639]\n",
      " [ 0.15766226  0.65663483  1.07545803]\n",
      " [-0.06709908 -0.29445107  1.47050378]] \t| empirical loss:  0.119973\n",
      "FINAL RESULTS Order 2:\n",
      "optimal weight vector:  [[-0.18414426 -0.14416919  0.1570062 ]\n",
      " [ 0.10728286 -0.04892337  0.05262928]\n",
      " [ 0.12677107  0.20074848  0.20217708]\n",
      " [-0.01538107  0.01261174  0.36630266]\n",
      " [ 0.04710642  0.09785964  0.07212742]\n",
      " [-0.1297786  -0.08783707 -0.03785284]\n",
      " [ 0.03888846 -0.09983442  0.23944285]\n",
      " [-0.1297786  -0.08783707 -0.03785284]\n",
      " [-0.11869969 -0.12377096 -0.29360815]\n",
      " [-0.09144085  0.02036214  0.14110097]\n",
      " [ 0.03888846 -0.09983442  0.23944285]\n",
      " [-0.09144085  0.02036214  0.14110097]\n",
      " [-0.14439166 -0.06104342  0.85270317]] \t| empirical loss:  0.000000\n",
      "FINAL RESULTS Order 3:\n",
      "optimal weight vector:  [[-0.10753647 -0.08776611  0.00826652]\n",
      " [ 0.05597916  0.00665781  0.05706418]\n",
      " [ 0.10528505  0.11076031  0.07942587]\n",
      " [ 0.00599365  0.00344845  0.13014322]\n",
      " [ 0.03879483  0.04733039  0.04710406]\n",
      " [-0.08205257 -0.06217145 -0.06517371]\n",
      " [ 0.02594199 -0.01878185  0.08538111]\n",
      " [-0.08205257 -0.06217145 -0.06517371]\n",
      " [-0.09770935 -0.08250608 -0.09645797]\n",
      " [-0.02680515  0.00838135 -0.01040726]\n",
      " [ 0.02594199 -0.01878185  0.08538111]\n",
      " [-0.02680515  0.00838135 -0.01040726]\n",
      " [-0.04017466 -0.03068839  0.23513605]\n",
      " [ 0.03166159 -0.02908816 -0.02115364]\n",
      " [-0.06091392  0.00180087  0.01602254]\n",
      " [ 0.00729277  0.04043063  0.06996322]\n",
      " [ 0.12236355  0.03749263  0.01667495]\n",
      " [ 0.07432435  0.11509537  0.15604158]\n",
      " [ 0.0494109   0.05252375  0.00145626]\n",
      " [ 0.00863942 -0.04561512  0.12910686]\n",
      " [ 0.0296849   0.05813994 -0.04239875]\n",
      " [-0.05579403 -0.04885784  0.42162433]] \t| empirical loss:  0.000000\n",
      "FINAL RESULTS Order 4:\n",
      "optimal weight vector:  [[-7.63525176e-02 -6.08036775e-02 -2.04006750e-02]\n",
      " [ 4.07276342e-02  1.02429959e-02  1.93063409e-02]\n",
      " [ 7.66879929e-02  7.42541909e-02  5.46071525e-02]\n",
      " [ 5.94388139e-05  5.21005864e-04  6.67463142e-02]\n",
      " [ 1.98256230e-02  2.12746781e-02  2.78725139e-02]\n",
      " [-4.99213039e-02 -3.23335720e-02 -3.14803801e-02]\n",
      " [ 2.61762594e-02  2.36065996e-04  2.28000603e-02]\n",
      " [-4.99213039e-02 -3.23335720e-02 -3.14803801e-02]\n",
      " [-7.98634599e-02 -6.85590034e-02 -6.00513131e-02]\n",
      " [-1.20272022e-02  4.11691638e-03 -3.11569014e-02]\n",
      " [ 2.61762594e-02  2.36065996e-04  2.28000603e-02]\n",
      " [-1.20272022e-02  4.11691638e-03 -3.11569014e-02]\n",
      " [-2.41750270e-02 -1.56950959e-02  8.96186536e-02]\n",
      " [ 2.58950167e-02 -6.88998482e-03 -6.55999977e-03]\n",
      " [-4.07616041e-02 -5.20261401e-03 -4.54894099e-03]\n",
      " [ 1.00823267e-04  1.60046929e-02  3.03942641e-02]\n",
      " [ 7.98478269e-02  2.68645850e-02  1.73785334e-02]\n",
      " [ 6.45562438e-02  8.42209496e-02  8.58833547e-02]\n",
      " [ 1.72106152e-02  1.93057277e-02  4.07188288e-02]\n",
      " [ 2.00879912e-02 -9.97545663e-03  3.07430921e-02]\n",
      " [ 1.94391707e-02  2.90111368e-02 -2.66841658e-02]\n",
      " [-2.63513195e-02 -1.95061812e-02  1.47165787e-01]\n",
      " [ 7.06751859e-04  3.28204642e-02  3.53639486e-02]\n",
      " [-1.81423360e-02 -3.42430722e-02 -3.43535582e-02]\n",
      " [ 1.64104668e-02 -2.09972353e-02 -1.72221556e-02]\n",
      " [-1.03989466e-01 -6.52258304e-02 -5.08710285e-02]\n",
      " [-4.83030195e-02 -6.55386000e-02 -7.55850191e-02]\n",
      " [-4.30535356e-02 -1.10880550e-02 -2.29475007e-02]\n",
      " [ 2.24739531e-02 -1.89922637e-02  5.03064439e-02]\n",
      " [ 2.15035339e-02  3.85944823e-02 -4.69865751e-02]\n",
      " [-2.57680806e-02 -2.47093299e-02  2.41529523e-01]] \t| empirical loss:  0.000000\n",
      "optimal weight vector:  [[-0.18445639  0.00672034  0.46064262]\n",
      " [ 0.30606436 -0.36489223  1.18325617]\n",
      " [ 0.22744634  0.4823012   0.9602905 ]\n",
      " [-0.11108059 -0.11006106  1.49275554]] \t| empirical loss:  0.028618\n",
      "FINAL RESULTS Order 2:\n",
      "optimal weight vector:  [[-0.06880634 -0.17125571 -0.00988027]\n",
      " [ 0.12807809 -0.22703103 -0.06353324]\n",
      " [ 0.07919405  0.24775081  0.28882104]\n",
      " [-0.13998214  0.14333659  0.59700813]\n",
      " [ 0.01301334  0.03044544  0.0839821 ]\n",
      " [ 0.011463   -0.03758322 -0.20076788]\n",
      " [-0.03614538 -0.01857355  0.37963374]\n",
      " [ 0.011463   -0.03758322 -0.20076788]\n",
      " [-0.2329129  -0.04986632 -0.1049544 ]\n",
      " [-0.00073599  0.07966112  0.0499065 ]\n",
      " [-0.03614538 -0.01857355  0.37963374]\n",
      " [-0.00073599  0.07966112  0.0499065 ]\n",
      " [ 0.0111765  -0.09511665  0.6288291 ]] \t| empirical loss:  0.000000\n",
      "FINAL RESULTS Order 3:\n",
      "optimal weight vector:  [[-4.82065969e-02 -9.56550606e-02 -1.25811849e-02]\n",
      " [ 2.90578502e-02 -5.07515086e-02  2.65507598e-02]\n",
      " [ 6.63153822e-02  1.00149379e-01  8.27685200e-02]\n",
      " [-3.81079327e-02  1.56521197e-02  1.49794984e-01]\n",
      " [ 1.12125738e-02 -2.02167745e-02  1.01207787e-02]\n",
      " [-6.63728342e-03  1.05120552e-02 -3.74632466e-02]\n",
      " [-9.36844291e-03  2.00757452e-02  1.20179348e-01]\n",
      " [-6.63728342e-03  1.05120552e-02 -3.74632466e-02]\n",
      " [-1.02880561e-01 -7.81442928e-02 -9.22327596e-02]\n",
      " [ 1.78770785e-02  1.45486688e-02 -1.81717918e-02]\n",
      " [-9.36844291e-03  2.00757452e-02  1.20179348e-01]\n",
      " [ 1.78770785e-02  1.45486688e-02 -1.81717918e-02]\n",
      " [ 1.30155624e-04 -6.68644696e-02  2.00775623e-01]\n",
      " [ 3.47496336e-02 -6.09355028e-02 -4.28428919e-02]\n",
      " [-2.47800765e-02  4.99782581e-02  3.80508996e-02]\n",
      " [-3.37406630e-02  5.22052583e-02  8.85230653e-02]\n",
      " [ 1.54360635e-02 -3.31198355e-02 -1.35143451e-03]\n",
      " [ 1.20225846e-01  1.06500990e-01  1.38279804e-01]\n",
      " [-2.54594351e-02  7.05849545e-03 -8.55891485e-03]\n",
      " [ 3.53201469e-02 -5.58813486e-02  1.15328172e-01]\n",
      " [-8.14482117e-03  7.94379762e-02 -1.84436511e-02]\n",
      " [-4.45805361e-02 -9.31542636e-03  4.44578063e-01]] \t| empirical loss:  0.000000\n",
      "FINAL RESULTS Order 4:\n",
      "optimal weight vector:  [[-0.02619318 -0.08076941 -0.04531473]\n",
      " [ 0.02217677 -0.04943355 -0.03720619]\n",
      " [ 0.03775973  0.08096854  0.06533651]\n",
      " [-0.03100072  0.03036834  0.09931001]\n",
      " [ 0.00884046 -0.02579092 -0.0170862 ]\n",
      " [-0.00908683  0.01315722  0.00875382]\n",
      " [-0.00495602  0.03243969  0.05768086]\n",
      " [-0.00908683  0.01315722  0.00875382]\n",
      " [-0.05814433 -0.05818504 -0.0521983 ]\n",
      " [ 0.02060564  0.00419597 -0.03455709]\n",
      " [-0.00495602  0.03243969  0.05768086]\n",
      " [ 0.02060564  0.00419597 -0.03455709]\n",
      " [-0.00290902 -0.05335801  0.05043859]\n",
      " [ 0.02145249 -0.05901926 -0.05717891]\n",
      " [-0.01467046  0.04813602  0.04494819]\n",
      " [-0.02093122  0.05445217  0.07031835]\n",
      " [ 0.01290699 -0.02989602 -0.03111916]\n",
      " [ 0.06790673  0.07698124  0.07843059]\n",
      " [-0.02475593  0.00839915  0.03450156]\n",
      " [ 0.02548058 -0.0468323  -0.0059553 ]\n",
      " [ 0.00184984  0.06907963  0.0144618 ]\n",
      " [-0.03140433  0.02358104  0.18993444]\n",
      " [-0.00185974  0.01199392  0.01522518]\n",
      " [ 0.00083034 -0.00947222 -0.01209734]\n",
      " [ 0.00085992 -0.0067175  -0.00156925]\n",
      " [ 0.00111788 -0.01037142 -0.00830901]\n",
      " [-0.09423468 -0.05342403 -0.0588165 ]\n",
      " [ 0.01302935  0.02904458  0.0104101 ]\n",
      " [ 0.00520272  0.00822146  0.07881944]\n",
      " [ 0.01838623  0.02801559 -0.05702283]\n",
      " [-0.00756507 -0.03451254  0.22998142]] \t| empirical loss:  0.000000\n",
      "optimal weight vector:  [[-3.29788179e-01 -5.63823831e-01  1.33110770e+00]\n",
      " [ 4.02207271e-01  1.76347693e-03  6.14691171e-01]\n",
      " [ 9.70753073e-02  3.52844566e-03  1.71883192e+00]\n",
      " [-8.07552614e-02  1.06853188e-03  1.31647273e+00]] \t| empirical loss:  0.051782\n",
      "FINAL RESULTS Order 2:\n",
      "optimal weight vector:  [[-0.15044987 -0.18489634  0.09430328]\n",
      " [ 0.11823904 -0.02020983  0.08153619]\n",
      " [ 0.1476943   0.14753067  0.13042788]\n",
      " [-0.04166092  0.01282862  0.37814104]\n",
      " [ 0.1184237  -0.01259689 -0.08908532]\n",
      " [-0.16270891 -0.0296454   0.04503271]\n",
      " [-0.05280394  0.03210129  0.43487282]\n",
      " [-0.16270891 -0.0296454   0.04503271]\n",
      " [-0.13814033 -0.1198699  -0.28045572]\n",
      " [-0.05632091 -0.04746215  0.0459327 ]\n",
      " [-0.05280394  0.03210129  0.43487282]\n",
      " [-0.05632091 -0.04746215  0.0459327 ]\n",
      " [-0.0747042  -0.15893177  0.70697544]] \t| empirical loss:  0.000000\n",
      "FINAL RESULTS Order 3:\n",
      "optimal weight vector:  [[-0.09358813 -0.13330132 -0.02670031]\n",
      " [ 0.0675904  -0.01770992  0.03945596]\n",
      " [ 0.10071471  0.11106721  0.0784699 ]\n",
      " [-0.00627577  0.02992386  0.1493666 ]\n",
      " [ 0.05314327 -0.02229476 -0.00821951]\n",
      " [-0.08852133 -0.01545661 -0.02721372]\n",
      " [ 0.00765339  0.0540611   0.14238913]\n",
      " [-0.08852133 -0.01545661 -0.02721372]\n",
      " [-0.1000568  -0.09269015 -0.10573376]\n",
      " [-0.01990302 -0.03046022 -0.04156391]\n",
      " [ 0.00765339  0.0540611   0.14238913]\n",
      " [-0.01990302 -0.03046022 -0.04156391]\n",
      " [-0.02166542 -0.09475707  0.18564009]\n",
      " [ 0.04173931 -0.02010193 -0.01083749]\n",
      " [-0.0680546  -0.00357377  0.00955613]\n",
      " [-0.00432959  0.03788932  0.06471053]\n",
      " [ 0.12215486  0.04906016  0.02644546]\n",
      " [ 0.08582869  0.07148697  0.12206088]\n",
      " [ 0.04800986  0.03542919 -0.01343773]\n",
      " [ 0.01698802 -0.03803318  0.13776983]\n",
      " [ 0.01590869  0.06699778 -0.03854178]\n",
      " [-0.06525837 -0.03720527  0.42900315]] \t| empirical loss:  0.000000\n",
      "FINAL RESULTS Order 4:\n",
      "optimal weight vector:  [[-0.06500421 -0.10161946 -0.06155649]\n",
      " [ 0.04642058 -0.01541981 -0.00592543]\n",
      " [ 0.07386676  0.08820475  0.06820111]\n",
      " [-0.00719289  0.03020636  0.09623129]\n",
      " [ 0.03311839 -0.02268512 -0.01693204]\n",
      " [-0.05758456 -0.00744519 -0.00605231]\n",
      " [ 0.01049911  0.05269536  0.07618439]\n",
      " [-0.05758456 -0.00744519 -0.00605231]\n",
      " [-0.07698636 -0.07670164 -0.06853592]\n",
      " [-0.00441234 -0.02019682 -0.05605534]\n",
      " [ 0.01049911  0.05269536  0.07618439]\n",
      " [-0.00441234 -0.02019682 -0.05605534]\n",
      " [-0.01076114 -0.06209285  0.04260475]\n",
      " [ 0.02667378 -0.01975123 -0.0182778 ]\n",
      " [-0.04118606  0.0041874   0.00394181]\n",
      " [-0.00247177  0.03391121  0.04737421]\n",
      " [ 0.07709691  0.03039631  0.02173058]\n",
      " [ 0.07164696  0.06348054  0.06437815]\n",
      " [ 0.01912166  0.01730472  0.03809548]\n",
      " [ 0.02028232 -0.01923126  0.02247388]\n",
      " [ 0.01478095  0.0523345  -0.00398314]\n",
      " [-0.03127551  0.00355746  0.16975613]\n",
      " [ 0.01910499 -0.01998417 -0.01954226]\n",
      " [-0.03179592  0.00477019  0.00623946]\n",
      " [-0.00139479  0.03115502  0.03684222]\n",
      " [-0.10778694 -0.05681456 -0.04173745]\n",
      " [-0.05311465 -0.04424688 -0.05461142]\n",
      " [-0.03877546 -0.02087861 -0.03351527]\n",
      " [ 0.00355077  0.03915828  0.11017325]\n",
      " [ 0.03148875  0.01031708 -0.07644876]\n",
      " [-0.01603587 -0.05490623  0.21048359]] \t| empirical loss:  0.000000\n",
      "optimal weight vector:  [[-0.15691365  0.03178801  0.35177901]\n",
      " [ 0.23364142 -0.37957181  1.43490282]\n",
      " [ 0.136241    0.39039636  1.32679125]\n",
      " [-0.1459654  -0.10978028  1.60900339]] \t| empirical loss:  0.059571\n",
      "FINAL RESULTS Order 2:\n",
      "optimal weight vector:  [[-0.0372992  -0.17321261 -0.01966081]\n",
      " [ 0.10028513 -0.22210165 -0.06101368]\n",
      " [ 0.01864558  0.23417274  0.34067931]\n",
      " [-0.11362429  0.15230974  0.56859376]\n",
      " [-0.01871333  0.03141086  0.09574739]\n",
      " [-0.02460078 -0.06467212 -0.13364671]\n",
      " [ 0.05679454  0.00543838  0.29398817]\n",
      " [-0.02460078 -0.06467212 -0.13364671]\n",
      " [-0.07985582 -0.00662299 -0.25305342]\n",
      " [ 0.0647023   0.08178548  0.01779192]\n",
      " [ 0.05679454  0.00543838  0.29398817]\n",
      " [ 0.0647023   0.08178548  0.01779192]\n",
      " [-0.05544226 -0.12457298  0.71356838]] \t| empirical loss:  0.000000\n",
      "FINAL RESULTS Order 3:\n",
      "optimal weight vector:  [[-3.51412701e-02 -9.20206280e-02 -7.22359894e-03]\n",
      " [ 3.18572717e-02 -4.57676752e-02  2.51486214e-02]\n",
      " [ 3.40620531e-02  8.44167122e-02  7.36424776e-02]\n",
      " [-4.08866228e-02  1.68153376e-02  1.47481409e-01]\n",
      " [-3.26308234e-03 -2.49614381e-02  4.62023075e-03]\n",
      " [-2.46866510e-02 -7.11939354e-03 -3.72172483e-02]\n",
      " [ 3.20792893e-02  4.56298239e-02  1.28670745e-01]\n",
      " [-2.46866510e-02 -7.11939354e-03 -3.72172483e-02]\n",
      " [-3.99960638e-02 -4.13657819e-02 -7.81415359e-02]\n",
      " [ 4.42241051e-02  2.65641470e-02 -1.02098477e-02]\n",
      " [ 3.20792893e-02  4.56298239e-02  1.28670745e-01]\n",
      " [ 4.42241051e-02  2.65641470e-02 -1.02098477e-02]\n",
      " [-3.64312932e-02 -8.99989031e-02  1.93644846e-01]\n",
      " [ 1.61077013e-02 -7.11642285e-02 -4.74290218e-02]\n",
      " [-1.12256450e-02  5.40850764e-02  4.34050906e-02]\n",
      " [-8.66340126e-03  6.93452962e-02  9.26424801e-02]\n",
      " [ 3.95973423e-02 -9.78324867e-03 -1.51987554e-03]\n",
      " [ 2.70453143e-02  4.93789263e-02  1.18991472e-01]\n",
      " [-5.95772697e-02 -6.34842840e-03 -2.01744280e-02]\n",
      " [ 3.98648638e-02 -5.48477554e-02  1.17331643e-01]\n",
      " [ 4.34408134e-02  1.11507477e-01 -8.03601948e-03]\n",
      " [-2.54736619e-02 -1.59230971e-05  4.49996780e-01]] \t| empirical loss:  0.000000\n",
      "FINAL RESULTS Order 4:\n",
      "optimal weight vector:  [[-2.34649468e-02 -8.15258238e-02 -4.23312270e-02]\n",
      " [ 2.52499228e-02 -4.60313854e-02 -3.68759902e-02]\n",
      " [ 2.27979792e-02  7.48151770e-02  5.63131979e-02]\n",
      " [-3.38692700e-02  2.99612835e-02  9.70295705e-02]\n",
      " [-6.01336412e-04 -2.96295503e-02 -2.28121837e-02]\n",
      " [-1.92194273e-02  5.07360585e-03  5.43275555e-03]\n",
      " [ 2.03709132e-02  4.70699019e-02  6.99535249e-02]\n",
      " [-1.92194273e-02  5.07360585e-03  5.43275555e-03]\n",
      " [-2.76201456e-02 -4.30995944e-02 -3.55928561e-02]\n",
      " [ 3.42230055e-02  9.84868575e-03 -2.63817874e-02]\n",
      " [ 2.03709132e-02  4.70699019e-02  6.99535249e-02]\n",
      " [ 3.42230055e-02  9.84868575e-03 -2.63817874e-02]\n",
      " [-2.71574957e-02 -6.68446714e-02  3.83176795e-02]\n",
      " [ 1.38612684e-02 -6.21233203e-02 -6.17699437e-02]\n",
      " [-9.87220707e-03  4.86540383e-02  4.88787202e-02]\n",
      " [-8.90094713e-03  6.13871766e-02  7.61580644e-02]\n",
      " [ 3.00562205e-02 -1.66065166e-02 -2.52191859e-02]\n",
      " [ 1.81025100e-02  5.03024580e-02  5.28075535e-02]\n",
      " [-4.46681342e-02 -1.21162545e-06  2.26429729e-02]\n",
      " [ 2.96113988e-02 -4.43759006e-02 -4.00364533e-03]\n",
      " [ 3.09899492e-02  8.49636150e-02  2.92581796e-02]\n",
      " [-2.52621047e-02  2.65099093e-02  1.93351880e-01]\n",
      " [-9.23867890e-03  8.47073660e-03  1.11229286e-02]\n",
      " [ 3.55259717e-03 -9.30865715e-03 -9.77453824e-03]\n",
      " [ 1.22854590e-02 -3.91055354e-05  3.91138954e-03]\n",
      " [-2.46533172e-02 -3.01395248e-02 -1.73197646e-02]\n",
      " [-1.90431451e-02 -1.11299060e-02 -2.15684467e-02]\n",
      " [ 3.72447327e-02  3.86322800e-02  2.52788005e-02]\n",
      " [ 3.42323831e-02  2.42109933e-02  9.34416652e-02]\n",
      " [ 3.00541544e-02  3.45540243e-02 -5.12252989e-02]\n",
      " [-8.51394871e-03 -3.57872781e-02  2.30039225e-01]] \t| empirical loss:  0.000000\n",
      "optimal weight vector:  [[-0.14749868  0.05696449  0.30334823]\n",
      " [ 0.59252327 -0.0452249   0.01119887]\n",
      " [ 0.32590952  0.54891516  0.58664779]\n",
      " [ 0.09915593  0.12738471  0.63064864]] \t| empirical loss:  0.022590\n",
      "FINAL RESULTS Order 2:\n",
      "optimal weight vector:  [[-0.11753465 -0.18426231 -0.10369459]\n",
      " [ 0.23204762 -0.18496685 -0.26984145]\n",
      " [ 0.09336359  0.25412828  0.24239396]\n",
      " [-0.08915907  0.16903637  0.35024909]\n",
      " [ 0.06655855  0.04779028  0.10037885]\n",
      " [-0.12928785 -0.09059933 -0.03306091]\n",
      " [ 0.037827    0.02265043 -0.08795955]\n",
      " [-0.12928785 -0.09059933 -0.03306091]\n",
      " [-0.20418018 -0.04253269 -0.04010193]\n",
      " [-0.06982847  0.06148945 -0.09079732]\n",
      " [ 0.037827    0.02265043 -0.08795955]\n",
      " [-0.06982847  0.06148945 -0.09079732]\n",
      " [-0.00707097 -0.08451181  0.15419558]] \t| empirical loss:  0.000000\n",
      "FINAL RESULTS Order 3:\n",
      "optimal weight vector:  [[-0.09139879 -0.12198673 -0.05726002]\n",
      " [ 0.0718101  -0.01725108 -0.03879811]\n",
      " [ 0.10085304  0.12334132  0.08701807]\n",
      " [-0.00436376  0.04039711  0.12321455]\n",
      " [ 0.05220109  0.00596309  0.03496305]\n",
      " [-0.09059281 -0.04788643 -0.01799329]\n",
      " [ 0.01567927  0.0462343  -0.0143365 ]\n",
      " [-0.09059281 -0.04788643 -0.01799329]\n",
      " [-0.10166981 -0.07927153 -0.06349704]\n",
      " [-0.01580631 -0.00325339 -0.09327645]\n",
      " [ 0.01567927  0.0462343  -0.0143365 ]\n",
      " [-0.01580631 -0.00325339 -0.09327645]\n",
      " [-0.01410405 -0.06761626  0.06927438]\n",
      " [ 0.04224448 -0.05521283 -0.05208536]\n",
      " [-0.06715089  0.02263733  0.0164694 ]\n",
      " [-0.002827    0.07448754  0.06987508]\n",
      " [ 0.12395495  0.0415121  -0.01395702]\n",
      " [ 0.08717186  0.08594043  0.11012218]\n",
      " [ 0.03947899  0.04043512  0.15014541]\n",
      " [ 0.02758782 -0.04859849 -0.06942532]\n",
      " [ 0.01683682  0.0971076  -0.02854932]\n",
      " [-0.04612136  0.01188896  0.11672894]] \t| empirical loss:  0.000000\n",
      "FINAL RESULTS Order 4:\n",
      "optimal weight vector:  [[-0.06424411 -0.10338035 -0.06065628]\n",
      " [ 0.05153338 -0.03135915 -0.04993634]\n",
      " [ 0.06913718  0.09980632  0.07048288]\n",
      " [-0.01182347  0.04188394  0.10236419]\n",
      " [ 0.02992345 -0.01350832  0.00098981]\n",
      " [-0.05439437 -0.01416249  0.00595812]\n",
      " [ 0.01194574  0.04385906  0.01083342]\n",
      " [-0.05439437 -0.01416249  0.00595812]\n",
      " [-0.07878247 -0.07075007 -0.04876944]\n",
      " [-0.00833184 -0.01226761 -0.07476951]\n",
      " [ 0.01194574  0.04385906  0.01083342]\n",
      " [-0.00833184 -0.01226761 -0.07476951]\n",
      " [-0.01280707 -0.05866713  0.02411559]\n",
      " [ 0.03775578 -0.04928614 -0.05237004]\n",
      " [-0.04999685  0.02726275  0.02607667]\n",
      " [-0.01261912  0.0596686   0.06286057]\n",
      " [ 0.08309863  0.01231251 -0.02226842]\n",
      " [ 0.06667031  0.07633096  0.0746388 ]\n",
      " [ 0.01572201  0.03104374  0.10575822]\n",
      " [ 0.02766734 -0.04404721 -0.06301765]\n",
      " [ 0.00647166  0.07235686 -0.00437791]\n",
      " [-0.0408219   0.0203603   0.09348952]\n",
      " [ 0.00587372  0.01622155  0.03268849]\n",
      " [-0.02171794 -0.02261457 -0.03119148]\n",
      " [ 0.00993321 -0.00077737 -0.01930467]\n",
      " [-0.10149707 -0.07165767 -0.0376092 ]\n",
      " [-0.05786684 -0.0318392  -0.04314013]\n",
      " [-0.04685682 -0.00492206 -0.07689634]\n",
      " [ 0.00966953  0.01352447 -0.02268555]\n",
      " [ 0.02418285  0.03104716 -0.03858006]\n",
      " [-0.02689577 -0.04164102  0.05220073]] \t| empirical loss:  0.000000\n",
      "optimal weight vector:  [[-0.16750443 -0.01704962  0.42011656]\n",
      " [ 0.34053502 -0.45764199  1.13084995]\n",
      " [ 0.23686314  0.29148259  1.05775011]\n",
      " [-0.11430474 -0.0604395   1.46999952]] \t| empirical loss:  0.121099\n",
      "FINAL RESULTS Order 2:\n",
      "optimal weight vector:  [[-0.1441303  -0.19648931  0.09291636]\n",
      " [ 0.22205452 -0.1999496  -0.21608537]\n",
      " [ 0.09408809  0.24303646  0.21491205]\n",
      " [-0.12161555  0.15207956  0.58624501]\n",
      " [ 0.07557518  0.06091248  0.0511077 ]\n",
      " [-0.13723483 -0.07713226  0.05884443]\n",
      " [-0.00330714 -0.04678954  0.11827165]\n",
      " [-0.13723483 -0.07713226  0.05884443]\n",
      " [-0.18718377 -0.03400441 -0.16436597]\n",
      " [-0.08367069  0.00784986 -0.08002378]\n",
      " [-0.00330714 -0.04678954  0.11827165]\n",
      " [-0.08367069  0.00784986 -0.08002378]\n",
      " [-0.0893646  -0.13325468  0.74143147]] \t| empirical loss:  0.000000\n",
      "FINAL RESULTS Order 3:\n",
      "optimal weight vector:  [[-0.08799422 -0.1185721  -0.00250807]\n",
      " [ 0.05959393 -0.03559493  0.00754875]\n",
      " [ 0.09461866  0.11502538  0.06899225]\n",
      " [ 0.00059055  0.04600615  0.17737616]\n",
      " [ 0.05474286  0.00985617  0.0222763 ]\n",
      " [-0.07807135 -0.03028204 -0.01775217]\n",
      " [-0.00858785  0.00996296  0.07102444]\n",
      " [-0.07807135 -0.03028204 -0.01775217]\n",
      " [-0.09816568 -0.07378365 -0.08580203]\n",
      " [-0.03738334 -0.03390215 -0.08122392]\n",
      " [-0.00858785  0.00996296  0.07102444]\n",
      " [-0.03738334 -0.03390215 -0.08122392]\n",
      " [-0.01404582 -0.07135127  0.22141389]\n",
      " [ 0.04462102 -0.05237401 -0.03201285]\n",
      " [-0.07131288  0.01669991  0.01981415]\n",
      " [-0.01042971  0.06369982  0.07366567]\n",
      " [ 0.11162032  0.02423217 -0.01665773]\n",
      " [ 0.08779575  0.08610509  0.13853331]\n",
      " [ 0.06935294  0.08439193  0.07275972]\n",
      " [ 0.00429368 -0.08489617  0.07152982]\n",
      " [-0.00437398  0.06856377 -0.07986797]\n",
      " [-0.07644522 -0.03798686  0.40482131]] \t| empirical loss:  0.000000\n",
      "FINAL RESULTS Order 4:\n",
      "optimal weight vector:  [[-0.05356641 -0.0906417  -0.05521098]\n",
      " [ 0.04482158 -0.04053803 -0.02866566]\n",
      " [ 0.05977232  0.08828816  0.07299403]\n",
      " [-0.00117702  0.05417559  0.11642908]\n",
      " [ 0.0328753  -0.00964226 -0.00476484]\n",
      " [-0.0456013  -0.00289926 -0.0058492 ]\n",
      " [-0.00251654  0.02420091  0.05413536]\n",
      " [-0.0456013  -0.00289926 -0.0058492 ]\n",
      " [-0.07284691 -0.06311886 -0.05733469]\n",
      " [-0.02574705 -0.03408174 -0.06178346]\n",
      " [-0.00251654  0.02420091  0.05413536]\n",
      " [-0.02574705 -0.03408174 -0.06178346]\n",
      " [ 0.00249001 -0.04161457  0.057147  ]\n",
      " [ 0.03946194 -0.04740801 -0.04818389]\n",
      " [-0.05214101  0.02463039  0.02655006]\n",
      " [-0.01650574  0.05454269  0.07118729]\n",
      " [ 0.07222429 -0.00167862 -0.00636067]\n",
      " [ 0.06539072  0.07466904  0.07683889]\n",
      " [ 0.0368376   0.05842938  0.07027542]\n",
      " [ 0.01817254 -0.05799008 -0.01273522]\n",
      " [-0.01560519  0.04529316 -0.00034144]\n",
      " [-0.03898989  0.01820525  0.18591019]\n",
      " [ 0.00754033  0.01883793  0.02030057]\n",
      " [-0.02141948 -0.0226567  -0.02264671]\n",
      " [ 0.00580593 -0.00668706 -0.00063244]\n",
      " [-0.08713542 -0.05378597 -0.04584052]\n",
      " [-0.06387971 -0.03901478 -0.04616152]\n",
      " [-0.0709449  -0.03614029 -0.03689412]\n",
      " [-0.01008773 -0.01467752  0.06485062]\n",
      " [ 0.00879333  0.01360669 -0.06580723]\n",
      " [-0.03015838 -0.05341206  0.21659313]] \t| empirical loss:  0.000000\n",
      "OVERALL LOSS degree 1:  0.02018318217607179\n",
      "OVERALL LOSS degree 2:  4.895007744319411e-31\n",
      "OVERALL LOSS degree 3:  6.046713851062978e-31\n",
      "OVERALL LOSS degree 4:  8.841109805039232e-31\n"
     ]
    }
   ],
   "source": [
    "# part = np.asarray(part)\n",
    "\n",
    "for i in range(len(part)): \n",
    "    validation_set = np.asarray([np.asarray(x) for x in part[i]]) # validation set\n",
    "    val_x, val_y = validation_set[:,:-1], validation_set[:,-1:] # extract x and y from validation set\n",
    "    training_set = [x for j, x in enumerate(part) if j != i] # training set\n",
    "    \n",
    "    train_x = [array[:,:-1] for array in training_set] # extract x from training set\n",
    "    train_y = [array[:,-1:] for array in training_set] # extract y from training set\n",
    "    train_x = np.asarray(train_x) # convert to numpy array\n",
    "    train_y = np.asarray(train_y)  # convert to numpy array\n",
    "    train_x = train_x.reshape(train_x.shape[0],train_x.shape[1],) # reshape to 2D array\n",
    "    train_y = train_y.reshape(train_y.shape[0],train_y.shape[1],) # reshape to 2D array\n",
    "\n",
    "    over_all_loss1, over_all_loss2, over_all_loss3, over_all_loss4 = 0, 0, 0, 0\n",
    "    w0, ls = PolynomialRegression(train_x, train_y, 1) # linear regression with polynomial mapping of degree 1\n",
    "    over_all_loss1 += ls\n",
    "    # print(\"FINAL RESULTS Order 1:\")\n",
    "    print(\"optimal weight vector: \", w0, \"\\t| empirical loss: \", \"{0:.6f}\".format(ls))\n",
    "    w0, ls = PolynomialRegression(train_x, train_y, 2) # linear regression with polynomial mapping of degree 2\n",
    "    over_all_loss2 += ls\n",
    "    print(\"FINAL RESULTS Order 2:\")\n",
    "    print(\"optimal weight vector: \", w0, \"\\t| empirical loss: \", \"{0:.6f}\".format(ls))\n",
    "    w0, ls = PolynomialRegression(train_x, train_y, 3) # linear regression with polynomial mapping of degree 2\n",
    "    over_all_loss3 += ls\n",
    "    print(\"FINAL RESULTS Order 3:\")\n",
    "    print(\"optimal weight vector: \", w0, \"\\t| empirical loss: \", \"{0:.6f}\".format(ls))\n",
    "    w0, ls = PolynomialRegression(train_x, train_y, 4) # linear regression with polynomial mapping of degree 2\n",
    "    over_all_loss4 += ls\n",
    "    print(\"FINAL RESULTS Order 4:\")\n",
    "    print(\"optimal weight vector: \", w0, \"\\t| empirical loss: \", \"{0:.6f}\".format(ls))\n",
    "print(\"OVERALL LOSS degree 1: \", over_all_loss1/len(part))\n",
    "print(\"OVERALL LOSS degree 2: \", over_all_loss2/len(part))\n",
    "print(\"OVERALL LOSS degree 3: \", over_all_loss3/len(part))\n",
    "print(\"OVERALL LOSS degree 4: \", over_all_loss4/len(part))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0 (tags/v3.8.0:fa919fd, Oct 14 2019, 19:37:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b337b16e1f284c9fe7de692799556d56c1809887abe3f5a49ffeb9e7df151cfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
