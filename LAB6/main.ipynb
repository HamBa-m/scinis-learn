{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from k_fold import *\n",
    "from splitData import *\n",
    "from algos.polynomial_regression import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data extraction\n",
    "data = []\n",
    "with open('temp_pre.csv', mode='r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        X, Y = [], []\n",
    "        X.append((1,int(row[\"temperature\"])))\n",
    "        Y.append(float(row[\"pressure\"]))\n",
    "        data.append([X, Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set:\n",
      " [[[(1, 20)], [0.0012]], [[(1, 40)], [0.006]], [[(1, 60)], [0.03]], [[(1, 80)], [0.09]], [[(1, 100)], [0.27]], [[(1, 120)], [0.75]], [[(1, 140)], [1.85]], [[(1, 160)], [4.2]], [[(1, 180)], [8.8]], [[(1, 200)], [17.3]], [[(1, 220)], [32.1]], [[(1, 260)], [96.0]], [[(1, 280)], [157.0]], [[(1, 320)], [376.0]], [[(1, 340)], [558.0]]]\n",
      "validation set\n",
      " [[[(1, 0)], [0.0002]], [[(1, 240)], [57.0]], [[(1, 300)], [247.0]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split data into 80% training and 20% validation sets\n",
    "train, valid = split(data)\n",
    "print(\"training set:\\n\",train)\n",
    "print(\"validation set\\n\", valid)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x:\n",
      " [[[  1  20]]\n",
      "\n",
      " [[  1  40]]\n",
      "\n",
      " [[  1  60]]\n",
      "\n",
      " [[  1  80]]\n",
      "\n",
      " [[  1 100]]\n",
      "\n",
      " [[  1 120]]\n",
      "\n",
      " [[  1 140]]\n",
      "\n",
      " [[  1 160]]\n",
      "\n",
      " [[  1 180]]\n",
      "\n",
      " [[  1 200]]\n",
      "\n",
      " [[  1 220]]\n",
      "\n",
      " [[  1 260]]\n",
      "\n",
      " [[  1 280]]\n",
      "\n",
      " [[  1 320]]\n",
      "\n",
      " [[  1 340]]]\n",
      "train_y:\n",
      " [[1.20e-03]\n",
      " [6.00e-03]\n",
      " [3.00e-02]\n",
      " [9.00e-02]\n",
      " [2.70e-01]\n",
      " [7.50e-01]\n",
      " [1.85e+00]\n",
      " [4.20e+00]\n",
      " [8.80e+00]\n",
      " [1.73e+01]\n",
      " [3.21e+01]\n",
      " [9.60e+01]\n",
      " [1.57e+02]\n",
      " [3.76e+02]\n",
      " [5.58e+02]]\n",
      "val_x:\n",
      " [[[  1   0]]\n",
      "\n",
      " [[  1 240]]\n",
      "\n",
      " [[  1 300]]]\n",
      "val_y:\n",
      " [[2.00e-04]\n",
      " [5.70e+01]\n",
      " [2.47e+02]]\n"
     ]
    }
   ],
   "source": [
    "# extract x from train\n",
    "train_x = [x for x, y in train]\n",
    "train_y = [y for x, y in train]\n",
    "val_x = [x for x, y in valid]\n",
    "val_y = [y for x, y in valid]\n",
    "train_x, train_y, val_x, val_y = np.asarray(train_x), np.asarray(train_y), np.asarray(val_x), np.asarray(val_y)\n",
    "\n",
    "print(\"train_x:\\n\", train_x)\n",
    "print(\"train_y:\\n\", train_y)\n",
    "print(\"val_x:\\n\", val_x)\n",
    "print(\"val_y:\\n\", val_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hicha\\Documents\\ENSIAS\\2A\\Machine Learning\\repo\\ML-from-scratch-with-Python\\LAB6\\algos\\polynomial_regression.py:90: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(w)\n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "Cannot cast ufunc 'svd_n_s' input from dtype('O') to dtype('float64') with casting rule 'same_kind'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m w0, ls \u001b[39m=\u001b[39m PolynomialRegression(train_x, train_y, \u001b[39m1\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFINAL RESULTS:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39moptimal weight vector: \u001b[39m\u001b[39m\"\u001b[39m, w0, \u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m| empirical loss: \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m{0:.6f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(ls))\n",
      "File \u001b[1;32mc:\\Users\\hicha\\Documents\\ENSIAS\\2A\\Machine Learning\\repo\\ML-from-scratch-with-Python\\LAB6\\algos\\polynomial_regression.py:109\u001b[0m, in \u001b[0;36mPolynomialRegression\u001b[1;34m(X, Y, q)\u001b[0m\n\u001b[0;32m    107\u001b[0m b \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(X_\u001b[39m.\u001b[39mT, Y) \n\u001b[0;32m    108\u001b[0m \u001b[39m# computes the pseudoinverse of A using a Singular-Value Decomposition algorithm\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m Aplus \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mpinv(A)\n\u001b[0;32m    110\u001b[0m \u001b[39m# solve the linear system A+.w = b\u001b[39;00m\n\u001b[0;32m    111\u001b[0m w \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(Aplus,b)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mpinv\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\hicha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\linalg\\linalg.py:1990\u001b[0m, in \u001b[0;36mpinv\u001b[1;34m(a, rcond, hermitian)\u001b[0m\n\u001b[0;32m   1988\u001b[0m     \u001b[39mreturn\u001b[39;00m wrap(res)\n\u001b[0;32m   1989\u001b[0m a \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39mconjugate()\n\u001b[1;32m-> 1990\u001b[0m u, s, vt \u001b[39m=\u001b[39m svd(a, full_matrices\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, hermitian\u001b[39m=\u001b[39;49mhermitian)\n\u001b[0;32m   1992\u001b[0m \u001b[39m# discard small singular values\u001b[39;00m\n\u001b[0;32m   1993\u001b[0m cutoff \u001b[39m=\u001b[39m rcond[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, newaxis] \u001b[39m*\u001b[39m amax(s, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, keepdims\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msvd\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\hicha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\linalg\\linalg.py:1648\u001b[0m, in \u001b[0;36msvd\u001b[1;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[0;32m   1645\u001b[0m         gufunc \u001b[39m=\u001b[39m _umath_linalg\u001b[39m.\u001b[39msvd_n_s\n\u001b[0;32m   1647\u001b[0m signature \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mD->DdD\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m isComplexType(t) \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39md->ddd\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m-> 1648\u001b[0m u, s, vh \u001b[39m=\u001b[39m gufunc(a, signature\u001b[39m=\u001b[39;49msignature, extobj\u001b[39m=\u001b[39;49mextobj)\n\u001b[0;32m   1649\u001b[0m u \u001b[39m=\u001b[39m u\u001b[39m.\u001b[39mastype(result_t, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   1650\u001b[0m s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mastype(_realType(result_t), copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: Cannot cast ufunc 'svd_n_s' input from dtype('O') to dtype('float64') with casting rule 'same_kind'"
     ]
    }
   ],
   "source": [
    "w0, ls = PolynomialRegression(train_x, train_y, 1)\n",
    "print(\"FINAL RESULTS:\")\n",
    "print(\"optimal weight vector: \", w0, \"\\t| empirical loss: \", \"{0:.6f}\".format(ls))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[120.]\n",
      " [300.]\n",
      " [ 60.]]\n",
      "[[7.50e-01]\n",
      " [2.47e+02]\n",
      " [3.00e-02]]\n",
      "[[-104.25436913]\n",
      " [   1.1133461 ]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [40], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(val_y)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(w0)\n\u001b[1;32m----> 5\u001b[0m loss \u001b[39m=\u001b[39m loss (val_x,val_y,w0)\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(loss)\n",
      "File \u001b[1;32mc:\\Users\\hicha\\Documents\\ENSIAS\\2A\\Machine Learning\\repo\\ML-from-scratch-with-Python\\LAB6\\algos\\polynomial_regression.py:49\u001b[0m, in \u001b[0;36mloss\u001b[1;34m(X, Y, w)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39mdescription: empirical error function\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[39margs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mreturn: average empirical error\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m     48\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(X) \u001b[39m# size of data sample\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m error \u001b[39m=\u001b[39m [(e(X[i], Y[i], w))\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X))] \u001b[39m# Mean-Squared Error (MSE)\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39msum(error)\u001b[39m/\u001b[39mn\n",
      "File \u001b[1;32mc:\\Users\\hicha\\Documents\\ENSIAS\\2A\\Machine Learning\\repo\\ML-from-scratch-with-Python\\LAB6\\algos\\polynomial_regression.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39mdescription: empirical error function\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[39margs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mreturn: average empirical error\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m     48\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(X) \u001b[39m# size of data sample\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m error \u001b[39m=\u001b[39m [(e(X[i], Y[i], w))\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X))] \u001b[39m# Mean-Squared Error (MSE)\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39msum(error)\u001b[39m/\u001b[39mn\n",
      "File \u001b[1;32mc:\\Users\\hicha\\Documents\\ENSIAS\\2A\\Machine Learning\\repo\\ML-from-scratch-with-Python\\LAB6\\algos\\polynomial_regression.py:36\u001b[0m, in \u001b[0;36me\u001b[1;34m(x, y, w)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39me\u001b[39m(x,y,w):\n\u001b[0;32m     28\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39m    description: error function between real y and predicted y\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m    args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39m    return: error between real y and predicted y\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m     \u001b[39mreturn\u001b[39;00m y \u001b[39m-\u001b[39m hs(x,w)\n",
      "File \u001b[1;32mc:\\Users\\hicha\\Documents\\ENSIAS\\2A\\Machine Learning\\repo\\ML-from-scratch-with-Python\\LAB6\\algos\\polynomial_regression.py:24\u001b[0m, in \u001b[0;36mhs\u001b[1;34m(x, w)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhs\u001b[39m(x,w):\n\u001b[0;32m     17\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m    description: polynomial regression hypothesis\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m    args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39m    return: matrcial product of x and w.T\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     \u001b[39mreturn\u001b[39;00m w\u001b[39m.\u001b[39;49mT \u001b[39m@\u001b[39;49m x\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 2)"
     ]
    }
   ],
   "source": [
    "# using the loss function to calculate the error\n",
    "print(val_x)\n",
    "print(val_y)\n",
    "print(w0)\n",
    "loss = loss(val_x,val_y,w0)\n",
    "print(loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27c5c81ded9e3cb6d5e2e7b5bcca8d6bd67c415cbc402cbae9698c8216c19643"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
